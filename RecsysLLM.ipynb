{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e7e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce72feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\daksh\\Downloads\\merged_sorted_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ccc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creates a hashmap to aggregate multiple reviews associated with each business.\n",
    "business_data = {}\n",
    "for _, row in df.iterrows():\n",
    "    business_id = row['business_id']\n",
    "    \n",
    "    if business_id not in business_data:\n",
    "       \n",
    "        business_data[business_id] = {\n",
    "            'name': row['name'],\n",
    "            'address': row['address'],\n",
    "            'city': row['city'],\n",
    "            'state': row['state'],\n",
    "            'postal_code': row['postal_code'],\n",
    "            'latitude': row['latitude'],\n",
    "            'longitude': row['longitude'],\n",
    "            'stars_x': [row['stars_x']] if pd.notnull(row['stars_y']) else 0, \n",
    "            'review_count': row['review_count'],\n",
    "            'is_open': row['is_open'],\n",
    "            'attributes': row['attributes'],  \n",
    "            'categories': row['categories'],  \n",
    "            'hours': row['hours'],  \n",
    "            'user_reviews': [row['text']], \n",
    "            'stars_y': [row['stars_y']] if pd.notnull(row['stars_y']) else 0\n",
    "        }\n",
    "    else:\n",
    "        if pd.notnull(row['stars_x']):\n",
    "            business_data[business_id]['stars_x'].append(row['stars_x'])\n",
    "        \n",
    "        if pd.notnull(row['stars_y']):\n",
    "            business_data[business_id]['stars_y'].append(row['stars_y'])\n",
    "       \n",
    "        business_data[business_id]['user_reviews'].append((row['text']))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe from hashmap for mapping.\n",
    "aggregated_df = pd.DataFrame.from_dict(business_data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the mean for business ratings\n",
    "def calculate_mean(stars_list):\n",
    "    if stars_list: \n",
    "        return round(sum(stars_list) / len(stars_list), 2)\n",
    "    else:\n",
    "        return None \n",
    "aggregated_df['stars_x'] = aggregated_df['stars_x'].apply(calculate_mean)\n",
    "aggregated_df['stars_y'] = aggregated_df['stars_y'].apply(calculate_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40017072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "aggregated_df.to_csv('aggregated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd601ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading csv file and splitting it in to chunks\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "loader =  CSVLoader(file_path = r\"C:\\Users\\daksh\\Downloads\\Recsys_using_RAG_ChatBot-main\\aggregated_data.csv\", encoding='UTF-8')\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embeddings using sentence Transformer for CSV file\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "\n",
    "model_args = {'device':'cpu'}\n",
    "\n",
    "encode_args = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     \n",
    "    model_kwargs=model_args, \n",
    "    encode_kwargs=encode_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468de90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f296e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I want to have a vegan food around santa Barbara\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "results = retriever.get_relevant_documents(query, num_results=7)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db2 = Chroma.from_documents(docs, embeddings, persist_directory=\"./chroma_db_1\")\n",
    "db2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = Chroma(embedding_function= embeddings,persist_directory=\"./chroma_db_1\")\n",
    "result = db3.similarity_search_with_score(query, 5)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92270b9-9572-444b-9030-0cbb51d142d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db3.similarity_search(query,5)[::-1]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e65c5-bb15-4e0f-b74e-cb58378b9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret = pd.read_csv('C:\\Users\\daksh\\Downloads\\Recsys_using_RAG_ChatBot-main\\aggregated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81238a4-ccb0-4d26-b6a4-db4b2c2bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define the PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"Business Review:\\n\"\"\"\n",
    "              \"\"\"Name: {Name}\\n\"\"\"\n",
    "              \"\"\"Address: {Address}, {City}, {State}, {PostalCode}\\n\"\"\"\n",
    "              \"\"\"Hours: {Hours}\\n\"\"\"\n",
    "              \"\"\"Rating: {Stars} stars\\n\"\"\",\n",
    "    input_variables=[\"Name\", \"Address\", \"City\", \"State\", \"PostalCode\", \"Hours\", \"Stars\"]\n",
    ")\n",
    "\n",
    "combined_reviews = \"\"\n",
    "\n",
    "# Iterate through documents\n",
    "for i in range(len(docs)):\n",
    "    row_value = docs[i].metadata.get('row', None)\n",
    "\n",
    "    if row_value is not None:\n",
    "        # Extracting data from the DataFrame\n",
    "        data = {\n",
    "            \"Name\": df_ret.iloc[row_value]['name'],\n",
    "            \"Address\": df_ret.iloc[row_value]['address'],\n",
    "            \"City\": df_ret.iloc[row_value]['city'],\n",
    "            \"State\": df_ret.iloc[row_value]['state'],\n",
    "            \"PostalCode\": df_ret.iloc[row_value]['postal_code'],\n",
    "            \"Hours\": df_ret.iloc[row_value]['hours'],\n",
    "            \"Stars\": df_ret.iloc[row_value]['stars_y']\n",
    "        }\n",
    "\n",
    "        # Format the prompt and append to combined_reviews\n",
    "        combined_reviews += prompt_template.format(**data) + \"\\n\"\n",
    "\n",
    "# Append the instruction at the end of the combined reviews\n",
    "final_prompt = combined_reviews + \"You are a smart recommender system, Please provide a recommendation based on this business information.\\nRecommend places from suggested additional context only and from file aggregated_data.csv \\nDo not suggest places on your own\\n Do not mention aggregated_data.csv file in your response and your response must suggest all Business Reviews included in prompt\"\n",
    "\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ae687-091d-4720-a394-341bfaa9ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def nvidia_api_call(query, api_key, invoke_url, fetch_url_format):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"content\": query,\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.7,\n",
    "        \"max_tokens\": 1024,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    session = requests.Session()\n",
    "    response = session.post(invoke_url, headers=headers, json=payload)\n",
    "\n",
    "    while response.status_code == 202:\n",
    "        request_id = response.headers.get(\"NVCF-REQID\")\n",
    "        fetch_url = fetch_url_format + request_id\n",
    "        response = session.get(fetch_url, headers=headers)\n",
    "\n",
    "    response.raise_for_status()\n",
    "    response_body = response.json()\n",
    "    return response_body['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b6956-e338-4a31-9cb1-d145ee242068",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "invoke_url = \"https://api.nvcf.nvidia.com/v2/nvcf/pexec/functions/0e349b44-440a-44e1-93e9-abe8dcb27158\"\n",
    "fetch_url_format = \"https://api.nvcf.nvidia.com/v2/nvcf/pexec/status/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b886b0a-a37c-4c4f-9351-a23eccfd340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = nvidia_api_call(final_prompt, api_key, invoke_url, fetch_url_format)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
